{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# MIDI-Trained Chord Recognition Model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Data Preprocessing \n",
    "## 1. Load and Extract from midi_folder"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import json\n",
    "import pretty_midi\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from collections import defaultdict\n",
    "import mido\n",
    "import io\n",
    "\n",
    "# define chord type templates: intervals relative to root\n",
    "CHORD_TEMPLATES = {\n",
    "    \"Major\":         {0, 4, 7},\n",
    "    \"Minor\":         {0, 3, 7},\n",
    "    \"Dominant 7th\":  {0, 4, 7, 10},\n",
    "    \"Diminished\":    {0, 3, 6},\n",
    "    \"Augmented\":     {0, 4, 8},\n",
    "}\n",
    "\n",
    "PITCH_CLASS_NAMES = ['C', 'C#', 'D', 'D#', 'E', 'F',\n",
    "                     'F#', 'G', 'G#', 'A', 'A#', 'B']\n",
    "\n",
    "# normalize chord, removing octave transpositions \n",
    "def normalize_chord(chord_tuple):\n",
    "    normalized_chord = {note % 12 for note in chord_tuple}  # keep only unique notes modulo 12\n",
    "    return tuple(sorted(normalized_chord))\n",
    "\n",
    "# identify and name chords \n",
    "def identify_named_chord(chord_tuple):\n",
    "    if not chord_tuple:\n",
    "        return \"Unknown\"\n",
    "\n",
    "    pitch_classes = sorted({p % 12 for p in chord_tuple})\n",
    "    for root in pitch_classes:\n",
    "        transposed = sorted({(p - root) % 12 for p in pitch_classes})\n",
    "        for label, template in CHORD_TEMPLATES.items():\n",
    "            if set(transposed) == template:\n",
    "                root_name = PITCH_CLASS_NAMES[root]\n",
    "                return f\"{root_name} {label}\"\n",
    "    return \"Unknown\"\n",
    "\n",
    "# fixed mapping for chord vocab: all 12 roots * templates\n",
    "def create_fixed_chord_vocab():\n",
    "    ALL_CHORDS = [\n",
    "        f\"{pitch} {chord_type}\"\n",
    "        for pitch in PITCH_CLASS_NAMES\n",
    "        for chord_type in CHORD_TEMPLATES.keys()\n",
    "    ]\n",
    "    chord_to_index = {chord: idx for idx, chord in enumerate(ALL_CHORDS)}\n",
    "    return chord_to_index\n",
    "\n",
    "# extract chord sequence\n",
    "def midi_to_chord_sequence(midi_file, merge_threshold=0.3):\n",
    "    #midi_data = pretty_midi.PrettyMIDI(midi_file)\n",
    "    \n",
    "    raw = mido.MidiFile(midi_file, clip=True)\n",
    "    merged = mido.MidiFile() \n",
    "    merged.ticks_per_beat = raw.ticks_per_beat\n",
    "    merged_track = mido.merge_tracks(raw.tracks)\n",
    "    merged.tracks.append(merged_track)\n",
    "    \n",
    "    # dump to memory buffer\n",
    "    buf = io.BytesIO()\n",
    "    merged.save(file=buf)\n",
    "    buf.seek(0)\n",
    "\n",
    "    midi_data = pretty_midi.PrettyMIDI(buf)\n",
    "\n",
    "    events = []\n",
    "    # for each note, add two events: on/off\n",
    "    for instrument in midi_data.instruments:\n",
    "        if instrument.is_drum:\n",
    "            continue\n",
    "        for note in instrument.notes:\n",
    "            events.append((note.start, 'on', note.pitch))\n",
    "            events.append((note.end, 'off', note.pitch))\n",
    "    \n",
    "    # ？? if need to sort(events.sort(key=lambda x: x[0]))\n",
    "    events.sort(key=lambda x: x[0])\n",
    "\n",
    "    active_notes = set()  # track notes that are in use\n",
    "    chords = []  # final list\n",
    "    previous_chord = None\n",
    "    chord_start_time = None\n",
    "    last_event_time = 0\n",
    "\n",
    "    # if note is starting, add to active set\n",
    "    # if note ending, remove it from active set\n",
    "    for time, action, pitch in events:\n",
    "        if action == 'on':\n",
    "            active_notes.add(pitch)\n",
    "        elif action == 'off':\n",
    "            active_notes.discard(pitch)\n",
    "\n",
    "        current_chord = normalize_chord(active_notes) if active_notes else None\n",
    "        chord_label = identify_named_chord(current_chord) if current_chord else None\n",
    "\n",
    "        # if chord changed\n",
    "        if chord_label != previous_chord:\n",
    "            if previous_chord is not None and chord_start_time is not None:\n",
    "                if time - chord_start_time >= merge_threshold:\n",
    "                    chords.append((round(chord_start_time, 3), round(time, 3), previous_chord))\n",
    "            chord_start_time = time\n",
    "            previous_chord = chord_label\n",
    "\n",
    "        last_event_time = time\n",
    "\n",
    "    # capture final chord if any\n",
    "    if previous_chord is not None and chord_start_time is not None:\n",
    "        chords.append((round(chord_start_time, 3), round(midi_data.get_end_time(), 3), previous_chord))\n",
    "\n",
    "    return chords, midi_data\n",
    "\n",
    "# timeframe-level feature extraction and align with chord labels\n",
    "def extract_frame_level_data(chords, midi_data, chord_to_index, frame_hop=1):\n",
    "    end_time = midi_data.get_end_time()\n",
    "    frame_times = np.arange(0, end_time, frame_hop)\n",
    "\n",
    "    chroma = midi_data.get_chroma(fs=int(1 / frame_hop))\n",
    "    chroma = chroma.T  # transpose to shape (frames, 12)\n",
    "\n",
    "    data = []\n",
    "\n",
    "    for i, t in enumerate(frame_times):\n",
    "        frame_feature = chroma[i] if i < len(chroma) else np.zeros(12)\n",
    "        label = None\n",
    "        for start, end, chord in chords:\n",
    "            if start <= t < end:\n",
    "                if chord in chord_to_index:\n",
    "                    label = chord_to_index[chord]\n",
    "                break\n",
    "        if label is not None:\n",
    "            data.append((t, frame_feature, label))\n",
    "    return data\n",
    "\n",
    "\n",
    "# process all midi files in the folder, save to CSV\n",
    "def process_midi_folder(input_folder, chord_csv, frame_csv, frame_hop=1):\n",
    "    chord_rows = []\n",
    "    frame_rows = []\n",
    "    chord_to_index = create_fixed_chord_vocab()\n",
    "\n",
    "    for root, _, files in os.walk(input_folder):\n",
    "        for fname in files:\n",
    "            if not fname.lower().endswith(('.mid','.midi')): continue\n",
    "            path = os.path.join(root, fname)\n",
    "            rel = os.path.relpath(path, input_folder)\n",
    "            try:\n",
    "                chords, midi = midi_to_chord_sequence(path)\n",
    "                # chord-level\n",
    "                for st, ed, ch in chords:\n",
    "                    chord_rows.append([rel, st, ed, ch])\n",
    "                # frame-level\n",
    "                frames = extract_frame_level_data(chords, midi, chord_to_index, frame_hop)\n",
    "                for t, feat, lbl in frames:\n",
    "                    frame_rows.append([rel, t, *feat, lbl])\n",
    "\n",
    "            except Exception as e:\n",
    "                print(f\"[ERROR] {rel}: {e}\")\n",
    "\n",
    "    # save to csv\n",
    "    chord_df = pd.DataFrame(chord_rows, columns=[\"filename\",\"start_time\",\"end_time\",\"chord\"])\n",
    "    chord_df.to_csv(chord_csv, index=False)\n",
    "    cols = [f\"chroma_{i}\" for i in range(12)]\n",
    "    frame_df = pd.DataFrame(frame_rows, columns=[\"filename\",\"time\", *cols, \"label\"])\n",
    "    frame_df.to_csv(frame_csv, index=False)\n",
    "\n",
    "    print(f\"✔ Saved chords to: {chord_csv}\")\n",
    "    print(f\"✔ Saved frames to: {frame_csv}\")\n",
    "    return chord_to_index\n",
    "\n",
    "\n",
    "# def process_midi_folder(midi_folder, chord_output_csv, frame_output_csv, frame_hop=1):\n",
    "#     chord_data = []\n",
    "#     frame_data = []\n",
    "\n",
    "#     chord_to_index = create_fixed_chord_vocab()\n",
    "\n",
    "#     for midi_file in os.listdir(midi_folder):\n",
    "#         if midi_file.endswith(\".mid\") or midi_file.endswith(\".midi\"):\n",
    "#             file_path = os.path.join(midi_folder, midi_file)\n",
    "#             try:\n",
    "#                 chords, midi_data = midi_to_chord_sequence(file_path)\n",
    "#                 for timestamp_start, timestamp_end, chord in chords:\n",
    "#                     chord_data.append([midi_file, timestamp_start, timestamp_end, chord])\n",
    "#             except Exception as e:\n",
    "#                 print(f\"Error processing {midi_file}: {e}\")\n",
    "\n",
    "#     # second pass to align frame-wise data using finalized vocab\n",
    "#     for midi_file in os.listdir(midi_folder):\n",
    "#         if midi_file.endswith(\".mid\") or midi_file.endswith(\".midi\"):\n",
    "#             file_path = os.path.join(midi_folder, midi_file)\n",
    "#             try:\n",
    "#                 chords, midi_data = midi_to_chord_sequence(file_path)\n",
    "#                 frame_entries = extract_frame_level_data(chords, midi_data, chord_to_index, frame_hop)\n",
    "#                 for t, feat, label in frame_entries:\n",
    "#                     frame_data.append([midi_file, round(t, 3)] + list(feat) + [label])\n",
    "#             except Exception as e:\n",
    "#                 print(f\"Error processing {midi_file} for frame-level: {e}\")\n",
    "\n",
    "#     # save chord segment CSV\n",
    "#     chord_df = pd.DataFrame(chord_data, columns=[\"filename\", \"start_time\", \"end_time\", \"chord\"])\n",
    "#     chord_df.to_csv(chord_output_csv, index=False)\n",
    "\n",
    "#     # save frame-level CSV\n",
    "#     feat_cols = [f\"chroma_{i}\" for i in range(12)]\n",
    "#     frame_df = pd.DataFrame(frame_data, columns=[\"filename\", \"time\"] + feat_cols + [\"label\"])\n",
    "#     frame_df.to_csv(frame_output_csv, index=False)\n",
    "\n",
    "#     print(f\"Chord segments saved to {chord_output_csv}\")\n",
    "#     print(f\"Frame-level data saved to {frame_output_csv}\")\n",
    "    \n",
    "#     return chord_to_index"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. Extract and Combine to csv file"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "✔ Saved chords to: output/chord_dataset.csv\n",
      "✔ Saved frames to: output/timeframe_dataset.csv\n"
     ]
    }
   ],
   "source": [
    "# paths\n",
    "output_dir = 'output'\n",
    "os.makedirs(output_dir, exist_ok=True)\n",
    "\n",
    "folder_to_process = 'midi_folder' # test use; change to 'lakh-midi-clean' for actual experiments\n",
    "\n",
    "base = os.path.basename(folder_to_process.rstrip(os.sep))\n",
    "chord_csv = os.path.join(output_dir, f\"chord_dataset.csv\")\n",
    "frame_csv = os.path.join(output_dir, f\"timeframe_dataset.csv\")\n",
    "vocab_json = os.path.join(output_dir, f\"chord_vocab.json\")\n",
    "\n",
    "chord_to_index = process_midi_folder(folder_to_process, chord_csv, frame_csv)\n",
    "\n",
    "with open(vocab_json, 'w') as f:\n",
    "    json.dump(chord_to_index, f, indent=2)\n",
    "\n",
    "\n",
    "# midi_folder = \"midi_folder\"  \n",
    "# chord_output_csv = \"chord_dataset.csv\"\n",
    "# frame_output_csv = \"timeframe_dataset.csv\"\n",
    "\n",
    "# chord_to_index = process_midi_folder(midi_folder, chord_output_csv, frame_output_csv)\n",
    "\n",
    "# with open(\"chord_vocab.json\", \"w\") as f:\n",
    "#     json.dump(chord_to_index, f)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3. One-hot Encoding"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "One-hot encoded data saved to output/timeframe_onehot.csv\n"
     ]
    }
   ],
   "source": [
    "# one-hot encoding \n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import os\n",
    "import json\n",
    "\n",
    "output_dir = \"output\"\n",
    "os.makedirs(output_dir, exist_ok=True)\n",
    "\n",
    "frame_csv_path = \"output/timeframe_dataset.csv\"\n",
    "chord_vocab_path = \"output/chord_vocab.json\"\n",
    "output_onehot_csv_path = os.path.join(output_dir, \"timeframe_onehot.csv\")\n",
    "\n",
    "\n",
    "# load from JSON file\n",
    "with open(chord_vocab_path, \"r\") as f:\n",
    "    chord_to_index = json.load(f)\n",
    "\n",
    "# reverse\n",
    "chord_to_index = {str(k): v for k, v in chord_to_index.items()}\n",
    "\n",
    "\n",
    "def one_hot_encode_labels(label_indices, num_classes):\n",
    "    return np.eye(num_classes)[label_indices]\n",
    "\n",
    "# load original timeframe-level dataset\n",
    "df = pd.read_csv(frame_csv_path)\n",
    "\n",
    "# get label col\n",
    "label_indices = df[\"label\"].astype(int).values\n",
    "\n",
    "# one-hot encoding \n",
    "num_classes = len(chord_to_index)\n",
    "one_hot = one_hot_encode_labels(label_indices, num_classes)\n",
    "\n",
    "# create DataFrame \n",
    "one_hot_columns = [f\"class_{i}\" for i in range(num_classes)]\n",
    "one_hot_df = pd.DataFrame(one_hot, columns=one_hot_columns)\n",
    "\n",
    "# combine with filename + time \n",
    "minimal_df = df[[\"filename\", \"time\"]].reset_index(drop=True)\n",
    "result_df = pd.concat([minimal_df, one_hot_df], axis=1)\n",
    "\n",
    "result_df.to_csv(output_onehot_csv_path, index=False)\n",
    "\n",
    "print(f\"One-hot encoded data saved to {output_onehot_csv_path}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Baseline Model: SVM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Classification Report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.47      0.71      0.57       185\n",
      "           1       0.50      0.38      0.43        24\n",
      "           2       0.47      0.37      0.41        19\n",
      "           3       0.00      0.00      0.00         1\n",
      "           4       0.00      0.00      0.00         2\n",
      "           5       0.55      0.68      0.61        31\n",
      "           6       0.75      0.46      0.57        13\n",
      "           7       0.00      0.00      0.00         4\n",
      "           8       0.00      0.00      0.00         1\n",
      "           9       0.00      0.00      0.00         2\n",
      "          10       0.59      0.74      0.66       133\n",
      "          11       0.53      0.47      0.49        45\n",
      "          12       0.57      0.29      0.38        14\n",
      "          13       0.00      0.00      0.00         1\n",
      "          14       0.00      0.00      0.00         1\n",
      "          15       0.69      0.74      0.71        65\n",
      "          16       0.00      0.00      0.00         5\n",
      "          17       0.50      0.17      0.25         6\n",
      "          18       0.00      0.00      0.00         1\n",
      "          19       0.00      0.00      0.00         2\n",
      "          20       0.64      0.65      0.64       102\n",
      "          21       0.53      0.48      0.51        48\n",
      "          22       0.00      0.00      0.00        10\n",
      "          23       0.00      0.00      0.00         2\n",
      "          25       0.65      0.63      0.64       115\n",
      "          26       0.72      0.62      0.67        21\n",
      "          27       0.00      0.00      0.00         9\n",
      "          30       0.68      0.65      0.67        26\n",
      "          31       0.83      0.33      0.48        15\n",
      "          32       0.00      0.00      0.00         2\n",
      "          33       0.00      0.00      0.00         2\n",
      "          35       0.58      0.66      0.62       169\n",
      "          36       0.70      0.30      0.42        23\n",
      "          37       0.67      0.10      0.17        20\n",
      "          38       0.00      0.00      0.00         1\n",
      "          40       0.44      0.62      0.52        39\n",
      "          41       0.67      0.25      0.36         8\n",
      "          42       0.00      0.00      0.00         5\n",
      "          43       0.00      0.00      0.00         1\n",
      "          45       0.63      0.71      0.67       100\n",
      "          46       0.53      0.24      0.33        38\n",
      "          47       0.50      0.09      0.15        11\n",
      "          48       0.00      0.00      0.00         2\n",
      "          50       0.55      0.63      0.59        82\n",
      "          51       0.29      0.20      0.24        10\n",
      "          52       0.00      0.00      0.00         4\n",
      "          53       0.00      0.00      0.00         2\n",
      "          55       0.47      0.52      0.49        31\n",
      "          56       0.48      0.28      0.35        39\n",
      "          57       0.83      0.29      0.43        17\n",
      "          58       0.00      0.00      0.00         3\n",
      "\n",
      "    accuracy                           0.57      1512\n",
      "   macro avg       0.33      0.26      0.28      1512\n",
      "weighted avg       0.55      0.57      0.54      1512\n",
      "\n",
      "Confusion Matrix:\n",
      "[[131   0   3 ...   2   0   0]\n",
      " [  1   9   0 ...   1   0   0]\n",
      " [  4   1   7 ...   0   0   0]\n",
      " ...\n",
      " [  6   0   0 ...  11   0   0]\n",
      " [  4   0   0 ...   0   5   0]\n",
      " [  3   0   0 ...   0   0   0]]\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import classification_report, confusion_matrix\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "\n",
    "frame_csv_path = \"output/timeframe_dataset.csv\"\n",
    "df = pd.read_csv(frame_csv_path)\n",
    "\n",
    "# split to train and test dataset\n",
    "feature_cols = [f\"chroma_{i}\" for i in range(12)]\n",
    "X = df[feature_cols].values\n",
    "y = df[\"label\"].values\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(\n",
    "    X, y, test_size=0.2, random_state=42, stratify=y\n",
    ")\n",
    "\n",
    "# standardize features\n",
    "scaler = StandardScaler()\n",
    "X_train_scaled = scaler.fit_transform(X_train)\n",
    "X_test_scaled = scaler.transform(X_test)\n",
    "\n",
    "# RBF kernel \n",
    "svm_model = SVC()\n",
    "svm_model.fit(X_train_scaled, y_train)\n",
    "\n",
    "y_pred = svm_model.predict(X_test_scaled)\n",
    "\n",
    "# print confusion metrics with zero_division fix\n",
    "print(\"Classification Report:\")\n",
    "print(classification_report(y_test, y_pred, zero_division=0))\n",
    "\n",
    "print(\"Confusion Matrix:\")\n",
    "print(confusion_matrix(y_test, y_pred))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. CNN Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import torch\n",
    "from torch.utils.data import DataLoader, TensorDataset\n",
    "from torch import nn\n",
    "import torch.nn.functional as F\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import StandardScaler, LabelEncoder\n",
    "from sklearn.metrics import classification_report, confusion_matrix\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# === 1. LOAD DATA ===\n",
    "df = pd.read_csv(\"output/timeframe_dataset.csv\")\n",
    "\n",
    "# Chroma features\n",
    "feature_cols = [f\"chroma_{i}\" for i in range(12)]\n",
    "X = df[feature_cols].values.astype(np.float32)\n",
    "y = df[\"label\"].values.astype(int)\n",
    "\n",
    "# === 2. REMAP LABELS ===\n",
    "le = LabelEncoder()\n",
    "y_dense = le.fit_transform(y)\n",
    "num_classes = len(le.classes_)\n",
    "\n",
    "# Optional: save mapping for interpretability\n",
    "index_to_label = dict(enumerate(le.classes_))\n",
    "\n",
    "# === 3. TRAIN/TEST SPLIT ===\n",
    "X_train, X_test, y_train, y_test = train_test_split(\n",
    "    X, y_dense, test_size=0.2, random_state=42, stratify=y_dense\n",
    ")\n",
    "\n",
    "# Standardize\n",
    "scaler = StandardScaler()\n",
    "X_train = scaler.fit_transform(X_train)\n",
    "X_test = scaler.transform(X_test)\n",
    "\n",
    "# Convert to PyTorch tensors\n",
    "X_train_tensor = torch.tensor(X_train).unsqueeze(1)  # (B, 1, 12)\n",
    "X_test_tensor = torch.tensor(X_test).unsqueeze(1)\n",
    "y_train_tensor = torch.tensor(y_train)\n",
    "y_test_tensor = torch.tensor(y_test)\n",
    "\n",
    "train_dataset = TensorDataset(X_train_tensor, y_train_tensor)\n",
    "test_dataset = TensorDataset(X_test_tensor, y_test_tensor)\n",
    "train_loader = DataLoader(train_dataset, batch_size=64, shuffle=True)\n",
    "test_loader = DataLoader(test_dataset, batch_size=64)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# cnn model architecture\n",
    "class ChromaCNN(nn.Module):\n",
    "    def __init__(self, num_classes):\n",
    "        super(ChromaCNN, self).__init__()\n",
    "        self.conv1 = nn.Conv1d(1, 16, kernel_size=3, padding=1)\n",
    "        self.conv2 = nn.Conv1d(16, 32, kernel_size=3, padding=1)\n",
    "        self.pool = nn.MaxPool1d(2)\n",
    "        self.fc1 = nn.Linear(32 * 6, 64)\n",
    "        self.fc2 = nn.Linear(64, num_classes)\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = F.relu(self.conv1(x))   # (B, 16, 12)\n",
    "        x = self.pool(x)            # (B, 16, 6)\n",
    "        x = F.relu(self.conv2(x))   # (B, 32, 6)\n",
    "        x = x.view(x.size(0), -1)   # flatten\n",
    "        x = F.relu(self.fc1(x))\n",
    "        return self.fc2(x)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[W NNPACK.cpp:61] Could not initialize NNPACK! Reason: Unsupported hardware.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1, Loss: 297.8409\n",
      "Epoch 2, Loss: 225.2875\n",
      "Epoch 3, Loss: 196.8446\n",
      "Epoch 4, Loss: 184.0336\n",
      "Epoch 5, Loss: 176.8714\n",
      "Epoch 6, Loss: 171.5461\n",
      "Epoch 7, Loss: 167.2862\n",
      "Epoch 8, Loss: 164.7154\n",
      "Epoch 9, Loss: 161.6453\n",
      "Epoch 10, Loss: 159.4607\n",
      "Epoch 11, Loss: 157.4819\n",
      "Epoch 12, Loss: 154.8853\n",
      "Epoch 13, Loss: 153.1711\n",
      "Epoch 14, Loss: 152.5662\n",
      "Epoch 15, Loss: 149.6895\n",
      "Epoch 16, Loss: 148.5393\n",
      "Epoch 17, Loss: 147.0645\n",
      "Epoch 18, Loss: 146.0917\n",
      "Epoch 19, Loss: 144.8855\n",
      "Epoch 20, Loss: 143.8104\n"
     ]
    }
   ],
   "source": [
    "# training loop\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "model = ChromaCNN(num_classes=num_classes).to(device)\n",
    "\n",
    "criterion = nn.CrossEntropyLoss()\n",
    "optimizer = torch.optim.Adam(model.parameters(), lr=0.001)\n",
    "\n",
    "for epoch in range(20):\n",
    "    model.train()\n",
    "    total_loss = 0\n",
    "    for X_batch, y_batch in train_loader:\n",
    "        X_batch, y_batch = X_batch.to(device), y_batch.to(device)\n",
    "        optimizer.zero_grad()\n",
    "        outputs = model(X_batch)\n",
    "        loss = criterion(outputs, y_batch)\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        total_loss += loss.item()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Classification Report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.50      0.72      0.59       185\n",
      "           1       0.62      0.42      0.50        24\n",
      "           2       0.45      0.47      0.46        19\n",
      "           3       0.00      0.00      0.00         1\n",
      "           4       1.00      0.50      0.67         2\n",
      "           5       0.61      0.65      0.62        31\n",
      "           6       0.55      0.46      0.50        13\n",
      "           7       0.67      0.50      0.57         4\n",
      "           8       0.00      0.00      0.00         1\n",
      "           9       0.00      0.00      0.00         2\n",
      "          10       0.64      0.71      0.67       133\n",
      "          11       0.53      0.53      0.53        45\n",
      "          12       0.83      0.36      0.50        14\n",
      "          13       0.00      0.00      0.00         1\n",
      "          14       0.00      0.00      0.00         1\n",
      "          15       0.75      0.75      0.75        65\n",
      "          16       0.60      0.60      0.60         5\n",
      "          17       0.00      0.00      0.00         6\n",
      "          18       0.00      0.00      0.00         1\n",
      "          19       0.00      0.00      0.00         2\n",
      "          20       0.62      0.75      0.68       102\n",
      "          21       0.56      0.56      0.56        48\n",
      "          22       0.33      0.10      0.15        10\n",
      "          23       0.00      0.00      0.00         2\n",
      "          24       0.63      0.63      0.63       115\n",
      "          25       0.78      0.67      0.72        21\n",
      "          26       1.00      0.11      0.20         9\n",
      "          27       0.63      0.73      0.68        26\n",
      "          28       0.71      0.33      0.45        15\n",
      "          29       0.00      0.00      0.00         2\n",
      "          30       0.00      0.00      0.00         2\n",
      "          31       0.68      0.62      0.65       169\n",
      "          32       0.50      0.43      0.47        23\n",
      "          33       0.62      0.25      0.36        20\n",
      "          34       0.33      1.00      0.50         1\n",
      "          35       0.53      0.54      0.53        39\n",
      "          36       0.60      0.38      0.46         8\n",
      "          37       0.25      0.20      0.22         5\n",
      "          38       0.00      0.00      0.00         1\n",
      "          39       0.71      0.66      0.68       100\n",
      "          40       0.54      0.39      0.45        38\n",
      "          41       0.60      0.27      0.38        11\n",
      "          42       0.00      0.00      0.00         2\n",
      "          43       0.65      0.65      0.65        82\n",
      "          44       0.22      0.20      0.21        10\n",
      "          45       0.50      0.25      0.33         4\n",
      "          46       0.00      0.00      0.00         2\n",
      "          47       0.50      0.48      0.49        31\n",
      "          48       0.36      0.41      0.38        39\n",
      "          49       0.75      0.53      0.62        17\n",
      "          50       0.00      0.00      0.00         3\n",
      "\n",
      "    accuracy                           0.59      1512\n",
      "   macro avg       0.42      0.35      0.36      1512\n",
      "weighted avg       0.60      0.59      0.58      1512\n",
      "\n"
     ]
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 1000x800 with 2 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# evaluation \n",
    "import seaborn as sns\n",
    "\n",
    "model.eval()\n",
    "all_preds = []\n",
    "all_labels = []\n",
    "\n",
    "with torch.no_grad():\n",
    "    for X_batch, y_batch in test_loader:\n",
    "        X_batch = X_batch.to(device)\n",
    "        outputs = model(X_batch)\n",
    "        preds = torch.argmax(outputs, dim=1).cpu().numpy()\n",
    "        all_preds.extend(preds)\n",
    "        all_labels.extend(y_batch.numpy())\n",
    "\n",
    "# Classification report\n",
    "print(\"Classification Report:\")\n",
    "print(classification_report(all_labels, all_preds, zero_division=0))\n",
    "\n",
    "# Confusion matrix\n",
    "cm = confusion_matrix(all_labels, all_preds)\n",
    "\n",
    "plt.figure(figsize=(10, 8))\n",
    "sns.heatmap(cm, cmap=\"Blues\", square=False, cbar=True, xticklabels=False, yticklabels=False)\n",
    "plt.title(\"Confusion Matrix\")\n",
    "plt.xlabel(\"Predicted\")\n",
    "plt.ylabel(\"Actual\")\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Hybrid Model (CNN+BiLSTM)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "# data loader\n",
    "# function to modify the input as small winddow of 16 frames\n",
    "def create_sequences(X, y, window_size):\n",
    "    sequences = []\n",
    "    labels = []\n",
    "\n",
    "    for i in range(len(X) - window_size):\n",
    "        seq = X[i:i + window_size]\n",
    "        label = y[i + window_size - 1]  # label for the last frame\n",
    "        sequences.append(seq)\n",
    "        labels.append(label)\n",
    "\n",
    "    return np.array(sequences), np.array(labels)\n",
    "  \n",
    "window_size = 16\n",
    "X_seq, y_seq = create_sequences(X, y_dense, window_size)\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(\n",
    "    X_seq, y_seq, test_size=0.2, random_state=42, stratify=y_seq\n",
    ")\n",
    "\n",
    "X_train_tensor = torch.tensor(X_train, dtype=torch.float32)\n",
    "X_test_tensor = torch.tensor(X_test, dtype=torch.float32)\n",
    "y_train_tensor = torch.tensor(y_train, dtype=torch.long)\n",
    "y_test_tensor = torch.tensor(y_test, dtype=torch.long)\n",
    "\n",
    "train_dataset = TensorDataset(X_train_tensor, y_train_tensor)\n",
    "test_dataset = TensorDataset(X_test_tensor, y_test_tensor)\n",
    "train_loader = DataLoader(train_dataset, batch_size=64, shuffle=True)\n",
    "test_loader = DataLoader(test_dataset, batch_size=64)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "# CNN+BiLSTM model architecture\n",
    "class CNN_BiLSTM(nn.Module):\n",
    "    def __init__(self, input_dim, hidden_dim, num_classes):\n",
    "        super(CNN_BiLSTM, self).__init__()\n",
    "        self.conv1 = nn.Conv1d(in_channels=input_dim, out_channels=32, kernel_size=3, padding=1)\n",
    "        self.relu = nn.ReLU()\n",
    "        self.bilstm = nn.LSTM(input_size=32, hidden_size=hidden_dim,\n",
    "                              num_layers=1, batch_first=True, bidirectional=True)\n",
    "        self.fc = nn.Linear(hidden_dim * 2, num_classes)  # *2 for bidirectional\n",
    "\n",
    "    def forward(self, x):\n",
    "        # x: (B, T, C) → we want conv over chroma channels per time\n",
    "        x = x.permute(0, 2, 1)      # (B, C, T)\n",
    "        x = self.relu(self.conv1(x))  # (B, 32, T)\n",
    "        x = x.permute(0, 2, 1)        # (B, T, 32)\n",
    "        output, _ = self.bilstm(x)    # (B, T, 2*hidden_dim)\n",
    "        x = output[:, -1, :]          # take last frame's output\n",
    "        return self.fc(x)             # (B, num_classes)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1, Loss: 265.0159\n",
      "Epoch 2, Loss: 179.9075\n",
      "Epoch 3, Loss: 156.1780\n",
      "Epoch 4, Loss: 143.0000\n",
      "Epoch 5, Loss: 134.3216\n",
      "Epoch 6, Loss: 127.5430\n",
      "Epoch 7, Loss: 122.4699\n",
      "Epoch 8, Loss: 116.7095\n",
      "Epoch 9, Loss: 111.5661\n",
      "Epoch 10, Loss: 108.1697\n",
      "Epoch 11, Loss: 104.0492\n",
      "Epoch 12, Loss: 99.9601\n",
      "Epoch 13, Loss: 96.8489\n",
      "Epoch 14, Loss: 93.2006\n",
      "Epoch 15, Loss: 91.2193\n",
      "Epoch 16, Loss: 87.6795\n",
      "Epoch 17, Loss: 84.1563\n",
      "Epoch 18, Loss: 82.3646\n",
      "Epoch 19, Loss: 80.2934\n",
      "Epoch 20, Loss: 77.9676\n"
     ]
    }
   ],
   "source": [
    "# model training \n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "model = CNN_BiLSTM(input_dim=12, hidden_dim=64, num_classes=num_classes).to(device)\n",
    "\n",
    "criterion = nn.CrossEntropyLoss()\n",
    "optimizer = torch.optim.Adam(model.parameters(), lr=0.001)\n",
    "\n",
    "for epoch in range(20):\n",
    "    model.train()\n",
    "    total_loss = 0\n",
    "    for X_batch, y_batch in train_loader:\n",
    "        X_batch, y_batch = X_batch.to(device), y_batch.to(device)\n",
    "        optimizer.zero_grad()\n",
    "        outputs = model(X_batch)\n",
    "        loss = criterion(outputs, y_batch)\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        total_loss += loss.item()\n",
    "    print(f\"Epoch {epoch+1}, Loss: {total_loss:.4f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Classification Report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.62      0.77      0.69       185\n",
      "           1       0.52      0.46      0.49        24\n",
      "           2       0.64      0.37      0.47        19\n",
      "           3       0.00      0.00      0.00         1\n",
      "           4       0.00      0.00      0.00         2\n",
      "           5       0.62      0.65      0.63        31\n",
      "           6       0.43      0.23      0.30        13\n",
      "           7       0.00      0.00      0.00         4\n",
      "           8       0.00      0.00      0.00         1\n",
      "           9       0.00      0.00      0.00         2\n",
      "          10       0.72      0.77      0.74       133\n",
      "          11       0.62      0.66      0.64        44\n",
      "          12       0.38      0.21      0.27        14\n",
      "          13       0.00      0.00      0.00         1\n",
      "          14       0.00      0.00      0.00         1\n",
      "          15       0.63      0.72      0.67        65\n",
      "          16       0.00      0.00      0.00         5\n",
      "          17       0.00      0.00      0.00         6\n",
      "          18       0.00      0.00      0.00         1\n",
      "          19       1.00      0.50      0.67         2\n",
      "          20       0.67      0.78      0.72       102\n",
      "          21       0.57      0.65      0.61        48\n",
      "          22       1.00      0.40      0.57        10\n",
      "          23       0.00      0.00      0.00         2\n",
      "          24       0.74      0.61      0.67       114\n",
      "          25       0.71      0.71      0.71        21\n",
      "          26       0.00      0.00      0.00         9\n",
      "          27       0.61      0.73      0.67        26\n",
      "          28       0.92      0.73      0.81        15\n",
      "          29       0.00      0.00      0.00         2\n",
      "          30       0.00      0.00      0.00         2\n",
      "          31       0.70      0.73      0.71       169\n",
      "          32       0.62      0.57      0.59        23\n",
      "          33       0.50      0.20      0.29        20\n",
      "          34       0.50      1.00      0.67         1\n",
      "          35       0.43      0.51      0.47        39\n",
      "          36       0.40      0.25      0.31         8\n",
      "          37       1.00      0.20      0.33         5\n",
      "          38       0.00      0.00      0.00         1\n",
      "          39       0.70      0.74      0.72       100\n",
      "          40       0.53      0.53      0.53        38\n",
      "          41       0.50      0.18      0.27        11\n",
      "          42       0.00      0.00      0.00         2\n",
      "          43       0.62      0.74      0.67        81\n",
      "          44       0.38      0.50      0.43        10\n",
      "          45       0.00      0.00      0.00         4\n",
      "          46       1.00      0.50      0.67         2\n",
      "          47       0.53      0.52      0.52        31\n",
      "          48       0.64      0.59      0.61        39\n",
      "          49       0.71      0.29      0.42        17\n",
      "          50       0.00      0.00      0.00         3\n",
      "\n",
      "    accuracy                           0.64      1509\n",
      "   macro avg       0.42      0.35      0.36      1509\n",
      "weighted avg       0.62      0.64      0.62      1509\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# evaluation \n",
    "model.eval()\n",
    "all_preds = []\n",
    "all_labels = []\n",
    "\n",
    "with torch.no_grad():\n",
    "    for X_batch, y_batch in test_loader:\n",
    "        X_batch = X_batch.to(device)\n",
    "        outputs = model(X_batch)\n",
    "        preds = torch.argmax(outputs, dim=1).cpu().numpy()\n",
    "        all_preds.extend(preds)\n",
    "        all_labels.extend(y_batch.numpy())\n",
    "\n",
    "print(\"Classification Report:\")\n",
    "print(classification_report(all_labels, all_preds, zero_division=0))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.10.16 ('clean-ml')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.16"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "1795191711aa80f8fd091f21fda29bf8e442f111547e266fd2a9700e97b03949"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
