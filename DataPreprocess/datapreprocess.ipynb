{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import json\n",
    "import pretty_midi\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from collections import defaultdict\n",
    "import mido\n",
    "import io\n",
    "\n",
    "# define chord type templates: intervals relative to root\n",
    "CHORD_TEMPLATES = {\n",
    "    \"Major\":         {0, 4, 7},\n",
    "    \"Minor\":         {0, 3, 7},\n",
    "    \"Dominant 7th\":  {0, 4, 7, 10},\n",
    "    \"Diminished\":    {0, 3, 6},\n",
    "    \"Augmented\":     {0, 4, 8},\n",
    "}\n",
    "\n",
    "PITCH_CLASS_NAMES = ['C', 'C#', 'D', 'D#', 'E', 'F',\n",
    "                     'F#', 'G', 'G#', 'A', 'A#', 'B']\n",
    "\n",
    "# normalize chord, removing octave transpositions \n",
    "def normalize_chord(chord_tuple):\n",
    "    normalized_chord = {note % 12 for note in chord_tuple}  # keep only unique notes modulo 12\n",
    "    return tuple(sorted(normalized_chord))\n",
    "\n",
    "# identify and name chords \n",
    "def identify_named_chord(chord_tuple):\n",
    "    if not chord_tuple:\n",
    "        return \"Unknown\"\n",
    "\n",
    "    pitch_classes = sorted({p % 12 for p in chord_tuple})\n",
    "    for root in pitch_classes:\n",
    "        transposed = sorted({(p - root) % 12 for p in pitch_classes})\n",
    "        for label, template in CHORD_TEMPLATES.items():\n",
    "            if set(transposed) == template:\n",
    "                root_name = PITCH_CLASS_NAMES[root]\n",
    "                return f\"{root_name} {label}\"\n",
    "    return \"Unknown\"\n",
    "\n",
    "# fixed mapping for chord vocab: all 12 roots * templates\n",
    "def create_fixed_chord_vocab():\n",
    "    ALL_CHORDS = [\n",
    "        f\"{pitch} {chord_type}\"\n",
    "        for pitch in PITCH_CLASS_NAMES\n",
    "        for chord_type in CHORD_TEMPLATES.keys()\n",
    "    ]\n",
    "    chord_to_index = {chord: idx for idx, chord in enumerate(ALL_CHORDS)}\n",
    "    return chord_to_index\n",
    "\n",
    "# extract chord sequence\n",
    "def midi_to_chord_sequence(midi_file, merge_threshold=0.3):\n",
    "    #midi_data = pretty_midi.PrettyMIDI(midi_file)\n",
    "    \n",
    "    raw = mido.MidiFile(midi_file, clip=True)\n",
    "    merged = mido.MidiFile() \n",
    "    merged.ticks_per_beat = raw.ticks_per_beat\n",
    "    merged_track = mido.merge_tracks(raw.tracks)\n",
    "    merged.tracks.append(merged_track)\n",
    "    \n",
    "    # dump to memory buffer\n",
    "    buf = io.BytesIO()\n",
    "    merged.save(file=buf)\n",
    "    buf.seek(0)\n",
    "\n",
    "    midi_data = pretty_midi.PrettyMIDI(buf)\n",
    "\n",
    "    events = []\n",
    "    # for each note, add two events: on/off\n",
    "    for instrument in midi_data.instruments:\n",
    "        if instrument.is_drum:\n",
    "            continue\n",
    "        for note in instrument.notes:\n",
    "            events.append((note.start, 'on', note.pitch))\n",
    "            events.append((note.end, 'off', note.pitch))\n",
    "    \n",
    "    # ？? if need to sort(events.sort(key=lambda x: x[0]))\n",
    "    events.sort(key=lambda x: x[0])\n",
    "\n",
    "    active_notes = set()  # track notes that are in use\n",
    "    chords = []  # final list\n",
    "    previous_chord = None\n",
    "    chord_start_time = None\n",
    "    last_event_time = 0\n",
    "\n",
    "    # if note is starting, add to active set\n",
    "    # if note ending, remove it from active set\n",
    "    for time, action, pitch in events:\n",
    "        if action == 'on':\n",
    "            active_notes.add(pitch)\n",
    "        elif action == 'off':\n",
    "            active_notes.discard(pitch)\n",
    "\n",
    "        current_chord = normalize_chord(active_notes) if active_notes else None\n",
    "        chord_label = identify_named_chord(current_chord) if current_chord else None\n",
    "\n",
    "        # if chord changed\n",
    "        if chord_label != previous_chord:\n",
    "            if previous_chord is not None and chord_start_time is not None:\n",
    "                if time - chord_start_time >= merge_threshold:\n",
    "                    chords.append((round(chord_start_time, 3), round(time, 3), previous_chord))\n",
    "            chord_start_time = time\n",
    "            previous_chord = chord_label\n",
    "\n",
    "        last_event_time = time\n",
    "\n",
    "    # capture final chord if any\n",
    "    if previous_chord is not None and chord_start_time is not None:\n",
    "        chords.append((round(chord_start_time, 3), round(midi_data.get_end_time(), 3), previous_chord))\n",
    "\n",
    "    return chords, midi_data\n",
    "\n",
    "# timeframe-level feature extraction and align with chord labels\n",
    "def extract_frame_level_data(chords, midi_data, chord_to_index, frame_hop=1):\n",
    "    end_time = midi_data.get_end_time()\n",
    "    frame_times = np.arange(0, end_time, frame_hop)\n",
    "\n",
    "    chroma = midi_data.get_chroma(fs=int(1 / frame_hop))\n",
    "    chroma = chroma.T  # transpose to shape (frames, 12)\n",
    "\n",
    "    data = []\n",
    "\n",
    "    for i, t in enumerate(frame_times):\n",
    "        frame_feature = chroma[i] if i < len(chroma) else np.zeros(12)\n",
    "        label = None\n",
    "        for start, end, chord in chords:\n",
    "            if start <= t < end:\n",
    "                if chord in chord_to_index:\n",
    "                    label = chord_to_index[chord]\n",
    "                break\n",
    "        if label is not None:\n",
    "            data.append((t, frame_feature, label))\n",
    "    return data\n",
    "\n",
    "\n",
    "# process all midi files in the folder, save to CSV\n",
    "def process_midi_folder(input_folder, chord_csv, frame_csv, frame_hop=1):\n",
    "    chord_rows = []\n",
    "    frame_rows = []\n",
    "    chord_to_index = create_fixed_chord_vocab()\n",
    "\n",
    "    for root, _, files in os.walk(input_folder):\n",
    "        for fname in files:\n",
    "            if not fname.lower().endswith(('.mid','.midi')): continue\n",
    "            path = os.path.join(root, fname)\n",
    "            rel = os.path.relpath(path, input_folder)\n",
    "            try:\n",
    "                chords, midi = midi_to_chord_sequence(path)\n",
    "                # chord-level\n",
    "                for st, ed, ch in chords:\n",
    "                    chord_rows.append([rel, st, ed, ch])\n",
    "                # frame-level\n",
    "                frames = extract_frame_level_data(chords, midi, chord_to_index, frame_hop)\n",
    "                for t, feat, lbl in frames:\n",
    "                    frame_rows.append([rel, t, *feat, lbl])\n",
    "\n",
    "            except Exception as e:\n",
    "                print(f\"[ERROR] {rel}: {e}\")\n",
    "\n",
    "    # save to csv\n",
    "    chord_df = pd.DataFrame(chord_rows, columns=[\"filename\",\"start_time\",\"end_time\",\"chord\"])\n",
    "    chord_df.to_csv(chord_csv, index=False)\n",
    "    cols = [f\"chroma_{i}\" for i in range(12)]\n",
    "    frame_df = pd.DataFrame(frame_rows, columns=[\"filename\",\"time\", *cols, \"label\"])\n",
    "    frame_df.to_csv(frame_csv, index=False)\n",
    "\n",
    "    print(f\"✔ Saved chords to: {chord_csv}\")\n",
    "    print(f\"✔ Saved frames to: {frame_csv}\")\n",
    "    return chord_to_index\n",
    "\n",
    "\n",
    "# def process_midi_folder(midi_folder, chord_output_csv, frame_output_csv, frame_hop=1):\n",
    "#     chord_data = []\n",
    "#     frame_data = []\n",
    "\n",
    "#     chord_to_index = create_fixed_chord_vocab()\n",
    "\n",
    "#     for midi_file in os.listdir(midi_folder):\n",
    "#         if midi_file.endswith(\".mid\") or midi_file.endswith(\".midi\"):\n",
    "#             file_path = os.path.join(midi_folder, midi_file)\n",
    "#             try:\n",
    "#                 chords, midi_data = midi_to_chord_sequence(file_path)\n",
    "#                 for timestamp_start, timestamp_end, chord in chords:\n",
    "#                     chord_data.append([midi_file, timestamp_start, timestamp_end, chord])\n",
    "#             except Exception as e:\n",
    "#                 print(f\"Error processing {midi_file}: {e}\")\n",
    "\n",
    "#     # second pass to align frame-wise data using finalized vocab\n",
    "#     for midi_file in os.listdir(midi_folder):\n",
    "#         if midi_file.endswith(\".mid\") or midi_file.endswith(\".midi\"):\n",
    "#             file_path = os.path.join(midi_folder, midi_file)\n",
    "#             try:\n",
    "#                 chords, midi_data = midi_to_chord_sequence(file_path)\n",
    "#                 frame_entries = extract_frame_level_data(chords, midi_data, chord_to_index, frame_hop)\n",
    "#                 for t, feat, label in frame_entries:\n",
    "#                     frame_data.append([midi_file, round(t, 3)] + list(feat) + [label])\n",
    "#             except Exception as e:\n",
    "#                 print(f\"Error processing {midi_file} for frame-level: {e}\")\n",
    "\n",
    "#     # save chord segment CSV\n",
    "#     chord_df = pd.DataFrame(chord_data, columns=[\"filename\", \"start_time\", \"end_time\", \"chord\"])\n",
    "#     chord_df.to_csv(chord_output_csv, index=False)\n",
    "\n",
    "#     # save frame-level CSV\n",
    "#     feat_cols = [f\"chroma_{i}\" for i in range(12)]\n",
    "#     frame_df = pd.DataFrame(frame_data, columns=[\"filename\", \"time\"] + feat_cols + [\"label\"])\n",
    "#     frame_df.to_csv(frame_output_csv, index=False)\n",
    "\n",
    "#     print(f\"Chord segments saved to {chord_output_csv}\")\n",
    "#     print(f\"Frame-level data saved to {frame_output_csv}\")\n",
    "    \n",
    "#     return chord_to_index"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "✔ Saved chords to: output/chord_dataset.csv\n",
      "✔ Saved frames to: output/timeframe_dataset.csv\n"
     ]
    }
   ],
   "source": [
    "# paths\n",
    "output_dir = 'output'\n",
    "os.makedirs(output_dir, exist_ok=True)\n",
    "\n",
    "folder_to_process = 'midi_folder' # test use; change to 'lakh-midi-clean' for actual experiments\n",
    "\n",
    "base = os.path.basename(folder_to_process.rstrip(os.sep))\n",
    "chord_csv = os.path.join(output_dir, f\"chord_dataset.csv\")\n",
    "frame_csv = os.path.join(output_dir, f\"timeframe_dataset.csv\")\n",
    "vocab_json = os.path.join(output_dir, f\"chord_vocab.json\")\n",
    "\n",
    "chord_to_index = process_midi_folder(folder_to_process, chord_csv, frame_csv)\n",
    "\n",
    "with open(vocab_json, 'w') as f:\n",
    "    json.dump(chord_to_index, f, indent=2)\n",
    "\n",
    "\n",
    "# midi_folder = \"midi_folder\"  \n",
    "# chord_output_csv = \"chord_dataset.csv\"\n",
    "# frame_output_csv = \"timeframe_dataset.csv\"\n",
    "\n",
    "# chord_to_index = process_midi_folder(midi_folder, chord_output_csv, frame_output_csv)\n",
    "\n",
    "# with open(\"chord_vocab.json\", \"w\") as f:\n",
    "#     json.dump(chord_to_index, f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "One-hot encoded data saved to output/timeframe_onehot.csv\n"
     ]
    }
   ],
   "source": [
    "# one-hot encoding \n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import os\n",
    "import json\n",
    "\n",
    "output_dir = \"output\"\n",
    "os.makedirs(output_dir, exist_ok=True)\n",
    "\n",
    "frame_csv_path = \"timeframe_dataset.csv\"\n",
    "chord_vocab_path = \"chord_vocab.json\"\n",
    "output_onehot_csv_path = os.path.join(output_dir, \"timeframe_onehot.csv\")\n",
    "\n",
    "\n",
    "# load from JSON file\n",
    "with open(chord_vocab_path, \"r\") as f:\n",
    "    chord_to_index = json.load(f)\n",
    "\n",
    "# reverse\n",
    "chord_to_index = {str(k): v for k, v in chord_to_index.items()}\n",
    "\n",
    "\n",
    "def one_hot_encode_labels(label_indices, num_classes):\n",
    "    return np.eye(num_classes)[label_indices]\n",
    "\n",
    "# load original timeframe-level dataset\n",
    "df = pd.read_csv(frame_csv_path)\n",
    "\n",
    "# get label col\n",
    "label_indices = df[\"label\"].astype(int).values\n",
    "\n",
    "# one-hot encoding \n",
    "num_classes = len(chord_to_index)\n",
    "one_hot = one_hot_encode_labels(label_indices, num_classes)\n",
    "\n",
    "# create DataFrame \n",
    "one_hot_columns = [f\"class_{i}\" for i in range(num_classes)]\n",
    "one_hot_df = pd.DataFrame(one_hot, columns=one_hot_columns)\n",
    "\n",
    "# combine with filename + time \n",
    "minimal_df = df[[\"filename\", \"time\"]].reset_index(drop=True)\n",
    "result_df = pd.concat([minimal_df, one_hot_df], axis=1)\n",
    "\n",
    "result_df.to_csv(output_onehot_csv_path, index=False)\n",
    "\n",
    "print(f\"One-hot encoded data saved to {output_onehot_csv_path}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Classification Report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.47      0.71      0.57       182\n",
      "           1       0.67      0.33      0.44        30\n",
      "           2       0.68      0.52      0.59        25\n",
      "           3       0.00      0.00      0.00         1\n",
      "           4       0.00      0.00      0.00         4\n",
      "           5       0.51      0.70      0.59        30\n",
      "           6       0.62      0.45      0.53        11\n",
      "           7       0.00      0.00      0.00         2\n",
      "           9       1.00      1.00      1.00         1\n",
      "          10       0.60      0.76      0.67       123\n",
      "          11       0.55      0.37      0.44        43\n",
      "          12       0.75      0.14      0.23        22\n",
      "          15       0.57      0.70      0.63        66\n",
      "          16       0.00      0.00      0.00         3\n",
      "          17       0.33      0.17      0.22         6\n",
      "          18       0.00      0.00      0.00         2\n",
      "          19       1.00      0.33      0.50         3\n",
      "          20       0.65      0.64      0.64       113\n",
      "          21       0.44      0.49      0.47        41\n",
      "          22       1.00      0.12      0.22         8\n",
      "          23       0.00      0.00      0.00         3\n",
      "          25       0.65      0.69      0.67       111\n",
      "          26       0.64      0.61      0.62        23\n",
      "          27       1.00      0.18      0.31        11\n",
      "          30       0.83      0.50      0.62        30\n",
      "          31       0.64      0.78      0.70         9\n",
      "          32       0.00      0.00      0.00         1\n",
      "          33       0.00      0.00      0.00         4\n",
      "          35       0.53      0.58      0.55       184\n",
      "          36       0.55      0.48      0.51        23\n",
      "          37       0.58      0.35      0.44        20\n",
      "          38       0.00      0.00      0.00         1\n",
      "          40       0.45      0.55      0.49        38\n",
      "          41       1.00      0.14      0.25         7\n",
      "          42       0.00      0.00      0.00         3\n",
      "          43       0.00      0.00      0.00         5\n",
      "          45       0.56      0.66      0.61        85\n",
      "          46       0.71      0.38      0.49        45\n",
      "          47       1.00      0.22      0.36         9\n",
      "          48       0.00      0.00      0.00         1\n",
      "          50       0.64      0.59      0.61        83\n",
      "          51       0.30      0.38      0.33         8\n",
      "          52       1.00      0.20      0.33         5\n",
      "          53       0.00      0.00      0.00         3\n",
      "          55       0.50      0.47      0.48        32\n",
      "          56       0.58      0.32      0.42        34\n",
      "          57       1.00      0.47      0.64        17\n",
      "          58       0.00      0.00      0.00         1\n",
      "\n",
      "    accuracy                           0.57      1512\n",
      "   macro avg       0.48      0.33      0.36      1512\n",
      "weighted avg       0.58      0.57      0.55      1512\n",
      "\n",
      "Confusion Matrix:\n",
      "[[129   2   3 ...   1   0   0]\n",
      " [  4  10   0 ...   0   0   0]\n",
      " [  3   0  13 ...   0   0   0]\n",
      " ...\n",
      " [  8   0   0 ...  11   0   0]\n",
      " [  0   0   0 ...   1   8   0]\n",
      " [  1   0   0 ...   0   0   0]]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/yunma/opt/anaconda3/lib/python3.9/site-packages/sklearn/metrics/_classification.py:1318: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "/Users/yunma/opt/anaconda3/lib/python3.9/site-packages/sklearn/metrics/_classification.py:1318: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "/Users/yunma/opt/anaconda3/lib/python3.9/site-packages/sklearn/metrics/_classification.py:1318: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import classification_report, confusion_matrix\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "\n",
    "frame_csv_path = \"output/timeframe_dataset.csv\"\n",
    "df = pd.read_csv(frame_csv_path)\n",
    "\n",
    "# split to train and test dataset\n",
    "feature_cols = [f\"chroma_{i}\" for i in range(12)]\n",
    "X = df[feature_cols].values\n",
    "y = df[\"label\"].values\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
    "\n",
    "# standardize features\n",
    "scaler = StandardScaler()\n",
    "X_train_scaled = scaler.fit_transform(X_train)\n",
    "X_test_scaled = scaler.transform(X_test)\n",
    "\n",
    "# RBF kernel \n",
    "svm_model = SVC()\n",
    "svm_model.fit(X_train_scaled, y_train)\n",
    "\n",
    "y_pred = svm_model.predict(X_test_scaled)\n",
    "\n",
    "# print confusion metrics\n",
    "print(\"Classification Report:\")\n",
    "print(classification_report(y_test, y_pred))\n",
    "\n",
    "print(\"Confusion Matrix:\")\n",
    "print(confusion_matrix(y_test, y_pred))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.9.12 ('base')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "56cbfe0d42addb724a40ecca5a9c269d2228ce218815f598e78d3b826c8b61fb"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
